import os
import io
import asyncio
import hashlib
from dataclasses import dataclass
from typing import List, Dict, Optional, Tuple

import pandas as pd
from aiogram import Bot, Dispatcher, F
from aiogram.types import Message, FSInputFile, CallbackQuery
from aiogram.filters import Command
from aiogram.utils.keyboard import InlineKeyboardBuilder
import xml.etree.ElementTree as ET


# =============================
# ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏
# =============================
TOKEN = os.getenv("TELEGRAM_TOKEN", "PASTE_TOKEN_HERE")
CURRENCY = "UAH"

# –ú–∞–ø–ø–∏–Ω–≥ –∫–æ–ª–æ–Ω–æ–∫ (–≤—Å–µ –≤ lower-case)
SRC = {
    "id": ["product code", "main sku", "–∫–æ–¥", "–∞—Ä—Ç–∏–∫—É–ª"],
    "name": ["name", "–Ω–∞–∑–≤–∞", "–Ω–∞–∑–≤–∞–Ω–∏–µ"],
    "category": ["category", "–∫–∞—Ç–µ–≥–æ—Ä—ñ—è", "–∫–∞—Ç–µ–≥–æ—Ä–∏—è"],
    "subcategory": ["subcategory", "–ø—ñ–¥–∫–∞—Ç–µ–≥–æ—Ä—ñ—è", "–ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è"],
    "qty": ["quantity", "–∫—ñ–ª—å–∫—ñ—Å—Ç—å", "–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ"],
    "price": ["special price", "price", "—Ü—ñ–Ω–∞", "—Ü–µ–Ω–∞"],
    "description": ["description", "–æ–ø–∏—Å", "–æ–ø–∏—Å–∞–Ω–∏–µ"],
    "photos": [
        "main photo", "photo1", "photo2", "photo3", "photo4", "photo5",
        "photo6", "photo7", "photo8", "photo 9", "photo 10", "photo 11", "photo 12",
        "–ø–æ—Å–∏–ª–∞–Ω–Ω—è_–∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è", "–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"
    ],
    "weight": ["weight", "kg", "–≤–∞–≥–∞,–∫–≥", "–≤–∞–≥–∞", "–≤–µ—Å"],
    "length": ["length", "–¥–æ–≤–∂–∏–Ω–∞,—Å–º", "–¥–ª–∏–Ω–∞,—Å–º"],
    "width": ["width", "—à–∏—Ä–∏–Ω–∞,—Å–º"],
    "height": ["height", "–≤–∏—Å–æ—Ç–∞,—Å–º", "–≤—ã—Å–æ—Ç–∞,—Å–º"],
    "params_primary": [
        ("size of the set", "–†–æ–∑–º—ñ—Ä –∫–æ–º–ø–ª–µ–∫—Ç—É"),
        ("size extra", "–î–æ–¥–∞—Ç–∫–æ–≤–∏–π —Ä–æ–∑–º—ñ—Ä"),
        ("sheet size", "–†–æ–∑–º—ñ—Ä –ø—Ä–æ—Å—Ç–∏—Ä–∞–¥–ª–∞"),
        ("size of the pillowcase", "–†–æ–∑–º—ñ—Ä –Ω–∞–≤–æ–ª–æ—á–∫–∏"),
        ("dimensions of the duvet cover", "–†–æ–∑–º—ñ—Ä –ø—ñ–¥–∫–æ–≤–¥—Ä–∏"),
        ("fabric type", "–¢–∏–ø —Ç–∫–∞–Ω–∏–Ω–∏"),
        ("composition", "–°–∫–ª–∞–¥"),
        ("density", "–©—ñ–ª—å–Ω—ñ—Å—Ç—å"),
        ("color", "–ö–æ–ª—ñ—Ä"),
        ("country of manufacture", "–ö—Ä–∞—ó–Ω–∞ –≤–∏—Ä–æ–±–Ω–∏–∫"),
        ("brand registration country", "–ö—Ä–∞—ó–Ω–∞ —Ä–µ—î—Å—Ç—Ä–∞—Ü—ñ—ó –±—Ä–µ–Ω–¥—É"),
        ("producer", "–í–∏—Ä–æ–±–Ω–∏–∫"),
        ("sheet", "–ü—Ä–æ—Å—Ç–∏—Ä–∞–¥–ª–æ"),
        ("pillowcase", "–ù–∞–≤–æ–ª–æ—á–∫–∞"),
        ("a feature of pillowcases", "–û—Å–æ–±–ª–∏–≤—ñ—Å—Ç—å –Ω–∞–≤–æ–ª–æ—á–æ–∫"),
        ("sheet with elastic band", "–ü—Ä–æ—Å—Ç–∏—Ä–∞–¥–ª–æ –Ω–∞ —Ä–µ–∑–∏–Ω—Ü—ñ"),
        ("gift packaging", "–ü–æ–¥–∞—Ä—É–Ω–∫–æ–≤–∞ —É–ø–∞–∫–æ–≤–∫–∞"),
        ("available layout options", "–î–æ—Å—Ç—É–ø–Ω—ñ –∫–æ–º–ø–ª–µ–∫—Ç–∞—Ü—ñ—ó"),
        ("fabrics \"a\" (top of the quilt)", "–¢–∫–∞–Ω–∏–Ω–∞ A (–≤–µ—Ä—Ö –∫–æ–≤–¥—Ä–∏)"),
        ("fabrics \"b\" (bed sheet)", "–¢–∫–∞–Ω–∏–Ω–∞ B (–ø—Ä–æ—Å—Ç–∏—Ä–∞–¥–ª–æ)"),
        ("bonus", "–ë–æ–Ω—É—Å")
    ],
}

PROM_XLS_COLS = [
    "–ö–æ–¥_—Ç–æ–≤–∞—Ä—É",
    "–ù–∞–∑–≤–∞_–ø–æ–∑–∏—Ü—ñ—ó",
    "–ù–∞–∑–≤–∞_–ø–æ–∑–∏—Ü—ñ—ó_—É–∫—Ä",
    "–û–ø–∏—Å",
    "–û–ø–∏—Å_—É–∫—Ä",
    "–¶—ñ–Ω–∞",
    "–í–∞–ª—é—Ç–∞",
    "–ö—ñ–ª—å–∫—ñ—Å—Ç—å",
    "–ü–æ—Å–∏–ª–∞–Ω–Ω—è_–∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è",
    "–í–∞–≥–∞,–∫–≥",
    "–®–∏—Ä–∏–Ω–∞,—Å–º",
    "–í–∏—Å–æ—Ç–∞,—Å–º",
    "–î–æ–≤–∂–∏–Ω–∞,—Å–º",
] + [
    col
    for i in range(1, 16)
    for col in (
        f"–ù–∞–∑–≤–∞_–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏_{i}",
        f"–û–¥–∏–Ω–∏—Ü—è_–≤–∏–º—ñ—Ä—É_–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏_{i}",
        f"–ó–Ω–∞—á–µ–Ω–Ω—è_–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏_{i}"
    )
]


# =============================
# üß© –£—Ç–∏–ª–∏—Ç—ã
# =============================

def normalize_df(df: pd.DataFrame) -> pd.DataFrame:
    """–ü—Ä–∏–≤–æ–¥–∏–º –∏–º–µ–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤."""
    df = df.copy()
    df.columns = [str(c).strip().lower() for c in df.columns]
    return df


def find_first_col(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:
    for c in candidates:
        if c in df.columns:
            return c
    return None


def build_image_list(row: pd.Series) -> List[str]:
    urls: List[str] = []
    for col in SRC["photos"]:
        if col in row and pd.notna(row[col]):
            parts = [p.strip() for p in str(row[col]).split(",") if str(p).strip()]
            urls.extend(parts)
    return list(dict.fromkeys(urls))[:10]


# =============================
# üîÑ –£—Ç–∏–ª–∏—Ç—ã —Å –ª–æ–≥–∞–º–∏
# =============================

def pick_price(row: pd.Series) -> Optional[float]:
    """–ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Ü–µ–Ω—É –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ float. –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏."""
    for c in SRC["price"]:
        if c in row and pd.notna(row[c]):
            val = str(row[c]).replace(",", ".").strip()
            try:
                price = float(val)
                print(f"[DEBUG] –¶–µ–Ω–∞ –Ω–∞–π–¥–µ–Ω–∞ –≤ –∫–æ–ª–æ–Ω–∫–µ '{c}': {price}")
                return price
            except ValueError:
                print(f"[DEBUG] –ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å '{val}' –≤ float –≤ –∫–æ–ª–æ–Ω–∫–µ '{c}'")
    print("[DEBUG] –¶–µ–Ω–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    return None


def build_image_list(row: pd.Series) -> List[str]:
    """–°–æ–±–∏—Ä–∞–µ–º –¥–æ 10 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –ª–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è."""
    urls: List[str] = []
    for col in SRC["photos"]:
        if col in row and pd.notna(row[col]):
            parts = [p.strip() for p in str(row[col]).split(",") if str(p).strip()]
            urls.extend(parts)
    urls = list(dict.fromkeys(urls))[:10]
    if not urls:
        print(f"[DEBUG] –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ —Å—Ç—Ä–æ–∫–µ —Å _id={row.get('id', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
    return urls


def merge_ru_ua(df_ru: pd.DataFrame, df_ua: pd.DataFrame) -> pd.DataFrame:
    """–û–±—ä–µ–¥–∏–Ω—è–µ–º RU –∏ UA —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –∫–æ–ª–æ–Ω–æ–∫ –∏ –ª–æ–≥–∞–º–∏."""
    df_ru = normalize_df(df_ru)
    df_ua = normalize_df(df_ua)

    col_id_ru = find_first_col(df_ru, SRC["id"])
    col_id_ua = find_first_col(df_ua, SRC["id"])
    if not col_id_ru or not col_id_ua:
        print("[ERROR] –ù–µ –Ω–∞–π–¥–µ–Ω—ã –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã –≤ –æ–¥–Ω–æ–º –∏–∑ —Ñ–∞–π–ª–æ–≤!")
        return df_ru

    col_name_ru = find_first_col(df_ru, SRC["name"]) or "–Ω–∞–∑–≤–∞–Ω–∏–µ"
    col_name_ua = find_first_col(df_ua, SRC["name"]) or "–Ω–∞–∑–≤–∞"

    col_descr_ru = find_first_col(df_ru, SRC["description"]) or "–æ–ø–∏—Å–∞–Ω–∏–µ"
    col_descr_ua = find_first_col(df_ua, SRC["description"]) or "–æ–ø–∏—Å"

    df_ru["_id"] = df_ru[col_id_ru].astype(str).str.strip()
    df_ua["_id"] = df_ua[col_id_ua].astype(str).str.strip()

    ua = df_ua[["_id", col_name_ua, col_descr_ua]].rename(
        columns={col_name_ua: "–ù–∞–∑–≤–∞_–ø–æ–∑–∏—Ü—ñ—ó_—É–∫—Ä", col_descr_ua: "–û–ø–∏—Å_—É–∫—Ä"}
    )

    merged = df_ru.merge(ua, on="_id", how="left")
    merged["–ù–∞–∑–≤–∞_–ø–æ–∑–∏—Ü—ñ—ó"] = merged[col_name_ru].astype(str)
    merged["–û–ø–∏—Å"] = merged[col_descr_ru].astype(str)

    print(f"[DEBUG] –û–±—ä–µ–¥–∏–Ω–µ–Ω–æ {len(merged)} —Å—Ç—Ä–æ–∫")
    return merged



# =============================
# Excel –∏ YML
# =============================

def to_prom_excel(df: pd.DataFrame) -> pd.DataFrame:
    rows: List[Dict] = []
    col_id = find_first_col(df, SRC["id"]) or "–∫–æ–¥"
    col_qty = find_first_col(df, SRC["qty"]) or "quantity"

    for _, r in df.iterrows():
        pid = str(r.get(col_id, "")).strip()
        if not pid:
            continue

        item: Dict[str, Optional[str]] = {c: "" for c in PROM_XLS_COLS}
        item["–ö–æ–¥_—Ç–æ–≤–∞—Ä—É"] = pid[:25]
        item["–ù–∞–∑–≤–∞_–ø–æ–∑–∏—Ü—ñ—ó"] = r.get("–ù–∞–∑–≤–∞_–ø–æ–∑–∏—Ü—ñ—ó", "")
        item["–ù–∞–∑–≤–∞_–ø–æ–∑–∏—Ü—ñ—ó_—É–∫—Ä"] = r.get("–ù–∞–∑–≤–∞_–ø–æ–∑–∏—Ü—ñ—ó_—É–∫—Ä", "")
        item["–û–ø–∏—Å"] = r.get("–û–ø–∏—Å", "")
        item["–û–ø–∏—Å_—É–∫—Ä"] = r.get("–û–ø–∏—Å_—É–∫—Ä", "")
        item["–¶—ñ–Ω–∞"] = pick_price(r) or ""
        item["–í–∞–ª—é—Ç–∞"] = CURRENCY
        item["–ö—ñ–ª—å–∫—ñ—Å—Ç—å"] = r.get(col_qty, "")
        item["–ü–æ—Å–∏–ª–∞–Ω–Ω—è_–∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è"] = ", ".join(build_image_list(r))

        # —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
        triplets: List[Tuple[str, str, str]] = []
        for eng, uk in SRC["params_primary"]:
            if eng in r and pd.notna(r[eng]):
                val = str(r[eng]).strip()
                if val:
                    triplets.append((uk, "", val))
        for i, (nm, unit, val) in enumerate(triplets[:15], start=1):
            item[f"–ù–∞–∑–≤–∞_–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏_{i}"] = nm
            item[f"–û–¥–∏–Ω–∏—Ü—è_–≤–∏–º—ñ—Ä—É_–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏_{i}"] = unit
            item[f"–ó–Ω–∞—á–µ–Ω–Ω—è_–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏_{i}"] = val

        rows.append(item)

    return pd.DataFrame(rows, columns=PROM_XLS_COLS)


def to_prom_yml(df: pd.DataFrame) -> str:
    col_id = find_first_col(df, SRC["id"]) or "–∫–æ–¥"
    col_qty = find_first_col(df, SRC["qty"]) or "quantity"

    yml = ET.Element("yml_catalog")
    shop = ET.SubElement(yml, "shop")
    offers = ET.SubElement(shop, "offers")

    for _, r in df.iterrows():
        base_id = str(r.get(col_id, "")).strip()
        if not base_id:
            continue

        offer = ET.SubElement(offers, "offer", id=base_id, available="true")
        ET.SubElement(offer, "name").text = str(r.get("–ù–∞–∑–≤–∞_–ø–æ–∑–∏—Ü—ñ—ó", ""))
        ET.SubElement(offer, "name_ua").text = str(r.get("–ù–∞–∑–≤–∞_–ø–æ–∑–∏—Ü—ñ—ó_—É–∫—Ä", ""))
        ET.SubElement(offer, "description").text = str(r.get("–û–ø–∏—Å", ""))
        ET.SubElement(offer, "description_ua").text = str(r.get("–û–ø–∏—Å_—É–∫—Ä", ""))

        price = pick_price(r)
        if price:
            ET.SubElement(offer, "price").text = str(price)
        ET.SubElement(offer, "currencyId").text = CURRENCY
        qty = r.get(col_qty, None)
        if pd.notna(qty):
            ET.SubElement(offer, "quantity_in_stock").text = str(qty)

        for url in build_image_list(r):
            ET.SubElement(offer, "picture").text = url

    xml_bytes = ET.tostring(yml, encoding="utf-8")
    return "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n" + xml_bytes.decode("utf-8")


# =============================
# ü§ñ –ë–æ—Ç
# =============================
@dataclass
class Session:
    desired_format: Optional[str] = None
    files: List[pd.DataFrame] = None


class PromBot:
    def __init__(self, token: str):
        self.bot = Bot(token)
        self.dp = Dispatcher()
        self.sessions: Dict[int, Session] = {}
        self._register_handlers()

    def _fmt_kb(self) -> InlineKeyboardBuilder:
        kb = InlineKeyboardBuilder()
        kb.button(text="üìÑ XLSX", callback_data="fmt:xlsx")
        kb.button(text="üßæ YML", callback_data="fmt:yml")
        kb.adjust(2)
        return kb

    def _ensure_session(self, uid: int) -> Session:
        if uid not in self.sessions:
            self.sessions[uid] = Session(desired_format=None, files=[])
        return self.sessions[uid]

    def _register_handlers(self):
        dp = self.dp

        @dp.message(Command("start"))
        async def start(message: Message):
            sess = self._ensure_session(message.from_user.id)
            sess.files.clear()
            await message.answer(
                "üöÄ –ü—Ä–∏–≤–µ—Ç! –û—Ç–ø—Ä–∞–≤—å –¥–≤–∞ Excel-—Ñ–∞–π–ª–∞ (RU –∏ UA).\n"
                "–í—ã–±–µ—Ä–∏ —Ñ–æ—Ä–º–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:",
                reply_markup=self._fmt_kb().as_markup(),
            )

        @dp.callback_query(F.data.startswith("fmt:"))
        async def pick_format(cb: CallbackQuery):
            fmt = cb.data.split(":", 1)[1]
            sess = self._ensure_session(cb.from_user.id)
            sess.desired_format = fmt
            sess.files.clear()
            await cb.message.answer(f"‚úÖ –§–æ—Ä–º–∞—Ç –≤—ã–±—Ä–∞–Ω: {fmt.upper()}. –ó–∞–≥—Ä—É–∑–∏ –¥–≤–∞ Excel-—Ñ–∞–π–ª–∞ (RU –∏ UA).")
            await cb.answer()

        @dp.message(F.document)
        async def receive_file(message: Message):
            sess = self._ensure_session(message.from_user.id)
            if not sess.desired_format:
                await message.answer("‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏ —Ñ–æ—Ä–º–∞—Ç (XLSX –∏–ª–∏ YML).")
                return

            file = await self.bot.get_file(message.document.file_id)
            buf = await self.bot.download_file(file.file_path)

            try:
                df = pd.read_excel(io.BytesIO(buf.read()))
                df = normalize_df(df)
                sess.files.append(df)
            except Exception as e:
                await message.answer(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è Excel: {e}")
                return

            if len(sess.files) < 2:
                await message.answer("üìé –§–∞–π–ª –ø–æ–ª—É—á–µ–Ω. –ñ–¥—É –≤—Ç–æ—Ä–æ–π Excel...")
                return

            df_ru, df_ua = sess.files
            merged = merge_ru_ua(df_ru, df_ua)

            if sess.desired_format == "xlsx":
                out_df = to_prom_excel(merged)
                out_path = f"prom_{message.from_user.id}.xlsx"
                out_df.to_excel(out_path, index=False)
                await message.answer_document(FSInputFile(out_path), caption="üìÑ –ì–æ—Ç–æ–≤–æ: XLSX –¥–ª—è Prom.ua")
                os.remove(out_path)
            else:
                xml_text = to_prom_yml(merged)
                out_path = f"prom_{message.from_user.id}.yml"
                with open(out_path, "w", encoding="utf-8") as f:
                    f.write(xml_text)
                await message.answer_document(FSInputFile(out_path), caption="üßæ –ì–æ—Ç–æ–≤–æ: YML –¥–ª—è Prom.ua")
                os.remove(out_path)

            sess.files.clear()

    async def run(self):
        print("[DEV] ‚úÖ Bot started")
        await self.dp.start_polling(self.bot)


if __name__ == "__main__":
    bot = PromBot(TOKEN)
    asyncio.run(bot.run())
